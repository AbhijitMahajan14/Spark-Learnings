{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec369a9d-cab1-459f-b3c8-77d460154195",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: DataFrame[Name: string, Salary: bigint]"
     ]
    }
   ],
   "source": [
    "data = [(\"Alice\", 6000), (\"Bob\", 4500), (\"Charlie\", 3000)]\n",
    "columns = [\"Name\", \"Salary\"]\n",
    "\n",
    "df= spark.createDataFrame(data,columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1910bbab-3797-41a8-92d1-b85621af8563",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n|   Name|Salary|status|\n+-------+------+------+\n|  Alice|  6000|     Y|\n|    Bob|  4500|     Y|\n|Charlie|  3000|     Y|\n+-------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "df.withColumn('status',when(df.Name != '','Y').otherwise('N')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aab9f4f-dd76-4544-919a-e1a3d5dd55b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+\n|   Name|Salary|High_Earner|\n+-------+------+-----------+\n|  Alice|  6000|          Y|\n|    Bob|  4500|          Y|\n|Charlie|  3000|          Y|\n+-------+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Name\",\"Salary\",when(df.Name != '','Y').otherwise('N').alias(\"High_Earner\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "041ec000-1992-42e6-bcb8-b63566bebe30",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----------+\n|   Name|Salary|High_Earner|\n+-------+------+-----------+\n|  Alice|  6000|          N|\n|    Bob|  4500|          N|\n|Charlie|  3000|          N|\n+-------+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Name\",\"Salary\",when(df.Salary.isNull(),'Y').otherwise('N').alias(\"High_Earner\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44549f08-949d-45ba-9a7e-9e665158659e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------------+\n|   Name|Salary|Salary_Category|\n+-------+------+---------------+\n|  Alice|  6000|           High|\n|    Bob|  4500|         Medium|\n|Charlie|  3000|            Low|\n+-------+------+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df_with_expr = df.withColumn(\n",
    "    \"Salary_Category\",\n",
    "    expr(\n",
    "        \"CASE WHEN Salary > 5000 THEN 'High' \" +\n",
    "        \"WHEN Salary > 3000 THEN 'Medium' \" +\n",
    "        \"ELSE 'Low' END\"\n",
    "    )\n",
    ")\n",
    "df_with_expr.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2946b6a-96da-47d6-a179-4293e8174c32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark: Case Function (When.Otherwise )",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
